---
layout: page
title: Wildcard
parent: Jongman Book Training
---

{: .no_toc }
## Table of Contents
{: .no_toc .text-delta }
- TOC
{:toc}

# Description
 정규표현식을 처리하는 문제다. `?`와 `*`가 있을 수 있다. `?`는 아무
 문자 1개와 대응되고 `*`는 0개 이상의 모든 문자에 대응된다. 문자열의
 길이는 `<= 100` 이다.

 문제 자체는 이건데, 출력 부분이 좀 트리키했다. 매칭되는 단어를
 *정렬*해서 출력해야 한다.

# Solution
 `?`는 그냥 아무 글자 하나랑 대응하면 되는데, `*`는 몇 글자를 맞출지
 알 수 없다. 일일이 다 해봐야 한다. 그래서 `*`를 어떻게 처리하는지가
 이 문제의 핵심이고, 대부분의 정규표현식 엔진들도 이 부분에 많은
 최적화가 이뤄진 걸로 알고 있다.

## Brute Force
 인덱스 `pos`를 가지고 패턴과 단어를 탐색해보자. 인덱스에서 패턴이 `?`
 이거나, 아니면 패턴과 단어의 글자가 같으면 쭉 스킵한다. 그러면
 처음으로 `?` 또는 같지 않은 단어가 나오는 곳에 위치하게 된다.

 이러고 나면 남은 경우의 수는 총 네 가지이다.
 1. 패턴과 단어가 **대응하지 않는다**. 매칭 실패다.
 2. **패턴**의 끝에 도달했다. 즉, 패턴에 `*`이 하나도 없다. 이때는 패턴
    길이랑 단어 길이가 같아야 매칭이다.
 3. **단어**의 끝에 먼저 도달했다. 패턴은 아직 남아있다. 만약에 남은
    패턴이 전부 `*`면 매칭이기 때문에 확인해봐야 한다. 그렇지 않으면
    매칭 실패이다.
 4. 패턴의 `pos` 위치에 `*`가 있다. 이게 가장 문제다. `*`가 몇 글자에
    대응할지 모르기 때문에, 가능한 모든 경우를 일일이 시도해봐야
    한다. 패턴에서는 `*` 만큼 하나 진행하고, 단어에서는 0부터 가능한
    경우 (즉, 단어 길이) 까지 모두 스킵해가면서 시도해본다. 그러다가
    매칭되는게 *하나라도 있으면* 매칭 성공이다.

 이걸 한땀 한땀 구현해보자.

## Code

``` python
def match_bf(p, w):
    pos = 0
    while pos < len(p) and pos < len(w) and (p[pos] == '?' or p[pos] == w[pos]):
	    # 빠르게 쭉 스킵
        pos += 1

    if pos == len(p):  # 2번 케이스
        return pos == len(w)

    if p[pos] == '*':
        # 여기서 3번의 성공 케이스와 4번을 한큐에 처리
        skip = 0
        while pos + skip <= len(w):
            if match_bf(p[pos+1:], w[pos+skip:]):
                return True
            skip += 1

    return False  # 1번 케이스, 3번의 실패 케이스
```


## Memoization - `O(n^3)`
 당연하지만 모든 경우를 살펴보기 때문에, 패턴에 `*`가 많거나 단어
 길이가 길면 위의 알고리즘은 기하급수적으로 느려진다. 중복이 있으면
 메모아이즈 할 수 있을텐데, 중복이 있을까?

 첫번째 루프 안에서 앞부분을 스킵하기 때문에, 패턴과 단어는 항상
 접미사가 된다. 문자열의 길이가 최대 100이기 때문에, 접미사의 개수는
 최대 101개이고, 따라서 재귀 호출이 101 x 101 = 10201 번 이상 호출되면
 부분 문제가 반드시 존재한다는 것을 뜻한다. 예를 들어서, 패턴이
 `*********a` 이고 단어가 `aaaaaaaaab` 라면, 길이가 각각 10이므로
 접미사의 개수는 최대 11개, 따라서 121번 이상 재귀호출이 일어난다면
 반복되는 부분 문제가 있다는 건데, 당장 첫번째 `*`를 처리하는데에만
 해도 단어에 대해서 `11 ^ 10` 번의 `skip` 검사를 하기 때문에, 무조건
 반복되는 부분 문제가 있음을 알 수 있다.

 따라서 이 부분을 캐싱해보자. 서브 스트링을 넘기지말고 인덱스를 넘겨서
 캐싱을 좀더 똑똑하게 할 수 있다.

## Code

```python
@lru_cache(maxsize=None)
def match_n3(p, pi, w, wi):
    while pi < len(p) and wi < len(w) and (p[pi] == '?' or p[pi] == w[wi]):
        # 역시나 빠르게 쭉 스킵
        pi += 1
        wi += 1

    if pi == len(p):
        # 2번 케이스
        return wi == len(w)

    if p[pi] == '*':
        # 역시 *에 일일이 글자를 대응해본다.
        skip = 0
        while wi + skip <= len(w):
            if match_n3(p, pi + 1, w, wi + skip):
                return True
            skip += 1

    return False
```

 여기서 패턴 `p`와 단어 `w`는 변하지 않고, 인덱스만 변한다. 사실 이
 인덱스만 캐싱하면 더 빠르긴 하다.

 패턴, 문자열 길이를 `n` 이라고 할 때, 부분 문제의 최대 개수는 `n^2`
 이다. 위의 캐싱 버전은 한번 호출될 때마다 최대 `n` 번 재귀호출 하므로
 (`skip`) 복잡도는 `O(n^3)`이 된다.

## Memoization - `O(n^2)`
 위의 코드는 첫번째 `*`를 찾고, `*`에 몇 글자를 대응할지를 반복문으로
 풀고 있기 때문에 추가적인 복잡도 `n`이 곱해진다. 만약 이 반복을
 없애버리고 캐싱을 활용하면 `O(n^2)` 으로 한 차원 복잡도를 낮출 수
 있을 것이다.

 먼저 빠르게 쭉 스킵하는 부분을 보자. 반복문으로 쭉 스킵하지 않고,
 일일이 싹 캐싱해두면 나중에 반복 문제를 만났을 때 더 빠르게 계산할 수
 있다. 따라서 그냥 재귀호출로 바꾸자.

 `skip` 체크를 하는 부분도 반복문을 없앨 수 있다. 이 부분을 풀어서
 설명하면 (1) `*`에 아무런 글자도 대응시키지 않거나 (2) 한 글자를
 추가로 대응시키거나, 이 두 가지를 반복하고 있다. 그러므로 0 글자와 한
 글자 대응을 모두 재귀호출로 확인하고 싹 캐싱해버리면 된다.

## Code

```python
@lru_cache(maxsize=None)
def match_n2(p, pi, w, wi):
    if pi < len(p) and wi < len(w) and (p[pi] == '?' or p[pi] == w[wi]):
        # 스킵하지 말고 전부 재귀로 캐싱함
        return match_n2(p, pi + 1, w, wi + 1)

    if pi == len(p):
        return wi == len(w)

    if p[pi] == '*':
        # 역시 skip을 전부 체크하는게 아니라 일일이 하나씩 다 재귀로 캐싱
        # (pi + 1, wi) : *에 0 글자 매칭
        # (pi, wi + 1) : *에 한 글자 매칭
        if match_n2(p, pi + 1, w, wi) or (wi < len(w) and match_n2(p, pi, w, wi + 1)):
            return True

    return False
```
